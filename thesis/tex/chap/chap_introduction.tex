\chapter{Introduction} \label{chap:introduction}
The very first model of an artificial neuron dates back to 1943, when two scientists, neurophysiologist Warren S. McCulloch and mathematician Walter Pitts, tried to imitate key features of biological neurons. The highly simplified model was further elaborated, which led to the concept of a perceptron, published by Frank Rosenblatt in 1958, and over the time to teachable systems nowadays known as artificial neural networks.

Some people hold the view that deep neural networks are close to produce the highly complex behaviour similar to what humans can do and solemnly call their conducts "artificial intelligence". In my opinion, today's AI designates a bunch of methods that have nothing to do with a general intelligence, but, yes, it can produce a human-like behaviour when solving one particular problem. To give one example speaking for all, we can come with Google translator, which started to use neural networks to increase fluency and accuracy when translating longer sentences. Similarly, NNs are becoming the state-of-the-art classification method in many other domains and one must admit that the results are often fascinating.

Well, we know that NNs can be trained to work very well for several tasks, however, the problem is that hardly ever we know why they work so well. The architectures are complicated and the number of parameters is enormous. In other words, we usually have a well-working black box.

When we deal with a real (not academical) problem, one often comes to a point when his or her network works well (let's say with the accuracy of $ 90\% $), but a customer asks for an accuracy of $ 98\% $ for example. Then we can either keep trying and spend months on tuning the black box mostly in a random manner, or, if we demystify what is going on inside the network, we can suggest reasonable and targeted improvements.

In this work, we focus on understanding the behaviour of feedforward neural networks classifying particular data. We do it by optimizing the structure, specifically by pruning parts of the network that are unimportant for the classification. The hypothesis is that networks are often oversized and many synapses are redundant. We also think that we can find some rules or patterns in the network if it consists of important synapses only.

This effort could possibly lead to a general knowledge of how to design networks and tailor them for the challenged problem. In effect, the dimensionality of the parameters is significantly reduced, which speeds up both learning and prediction.

\section{State of the Art} \label{sec:state_of_the_art}
Optimization is a term of a broad meaning. In \citep{orhan:symmetry}, they try to break symmetries in a network in order to improve its performance. They do it by adding so-called "skip connections", which can also be considered as a kind of optimization. From another point of view, the problem could rest in an optimization of the crucial network learning algorithm (GDA).

In this study we rather focus on making networks small and simple. Having the smallest model that perfectly fits the classified data has two crucial advantages: 1) good generalization; 2) good chance that we will understand how the classification works.

There are two ways of how to end up with a small model that fits the data:

\begin{enumerate}
\item build a network from scratch by adding single parts (neurons, synapses) until a required performance is reached;
\item train a network that is larger than necessary and then remove the parts that are not needed.
\end{enumerate}

The first approach is left out for the future work, and we focus on the second course of action, which is called network \textit{pruning}. The general approach of a pruning procedure consists of these steps:

\begin{enumerate}
\item choose an oversized network architecture;
\item train the network until a reasonable solution is obtained;
\item delete a part of network (usually a synapse);
\item if the classification error has not grown, go to step 2), otherwise finish.
\end{enumerate}

The key question is how to identify the parts that can be deleted without an increase of the error. A good survey of published pruning methods is provided in \citep{reed:pa_survey}. The author starts with hypothetical calculations of what will happen if we use a brute force and remove the elements one by one. It ends up with a complexity of $ O(MW^3) $, where $ M $ is the number of samples and $ W $ is the number of network elements - slow for large networks. 

The pruning methods described below take a less direct approach and they basically differ one from each other in how they identify the unimportant network parts. In \citep{reed:pa_survey}, the methods are divided into two groups:
\begin{itemize}
\item \textit{sensitivity calculation methods};

These methods estimate the sensitivity of the error function to removal of an element; the elements with the least effect can then be removed.
 
\item \textit{penalty-term methods}.

These methods modify the cost function so that backpropagation based on the function drives unnecessary parameters zero and, in effect, removes them during training.
\end{itemize}

Since the cost function could include sensitivity terms, there is some overlap in these groups and as our method would better fit to the first group, we focus on three published methods based on sensitivity calculations.

\subsection*{Skeletonization} \label{ssec:skeletonization}
In \citep{mozer:skeletonization} they introduce a measure called relevance $ \rho $ of a synapse, which is an error when the synapse is removed minus the error when the synapse is left in place.

The value is approximated using a gating term $ \alpha $ for each unit such that

\begin{equation}
o_j = f(\displaystyle{\sum_i w_{ji} \cdot \alpha_i \cdot o_i})
\end{equation}

where $ o_j $ is the activity of neuron $ j $, $ w_{ji} $ is the weight from neuron $ i $ to neuron $ j $ and $ f(\cdot) $ is the \textit{Sigmoid} function. If $ \alpha = 0 $, the synapse has no influence on the network; if $ \alpha = 1 $, the synapse behaves normally. The relevance estimation is then given by the derivative from backpropagation

\begin{equation}
\hat{\rho_i} = - \left.\frac{\partial E^l}{\partial \alpha_i}\right\rvert_{\alpha_i = 1}
\end{equation}

Rather than the usual sum of squared errors, the error $ E^l $ (\cref{eq:skeletonization_error}) is used to measure relevance, because it works better when the error is small.

\begin{equation} \label{eq:skeletonization_error}
E^l = \sum |t_{pj} - o_{pj}|
\end{equation}

The authors claim the method works well for understanding the behaviour of a network in terms of "rules", which is shown on the RPE problem and on Michalski's trains (both these examples are also presented in this study for comparison).

\subsection*{Optimal Brain Damage} \label{ssec:optimal_brain_damage}
In \citep{lecun:obd} they use this ambitious title for a study that also tries to identify the unimportant weights and remove them from a network. Their measure is called "saliency" of a weight and it is estimated by the second derivative of the error with respect to the weight.

They compute the Hessian matrix $ H $ containing elements $ h_{ij} $.

\begin{equation}
h_{ij} = \frac{\partial^2 E}{\partial w_i \partial w_j}
\end{equation}

Since H is a very large matrix, they make a simplifying assumption that the off-diagonal terms of $ H $ are zero. This leaves

\begin{equation}
\delta E \approx \frac{1}{2} \displaystyle{\sum_i h_{ii} \cdot \delta \cdot w_i^2}
\end{equation}

It turns out that the second derivatives $ h_{kk} $ can be calculated by a modified back-propagation rule. The "saliency" $ s_k $ of weight $ w_k $ is then

\begin{equation}
s_k = h_{kk} \cdot \frac{w_k^2}{2}
\end{equation}

In each pruning step, weights with low saliencies are deleted. The method is tested on the MNIST dataset \citep{lecun:mnist}, which is also used to show the developed method in this study.

\subsection*{Karnin's Measure} \label{ssec:karnins_measure}
The measure published in \citep{karnin:pa} is the most similar to the one used by the developed PA. The author also used the change in weight during the pruning process to compute a measure called "sensitivity" for each synapse. The sensitivity $ S_{ij} $ of weight $ w_{ij} $ is given as

\begin{equation}
S_{ij} = - \frac{E(w^f) - E(w^i)}{w^f - w^i} \cdot w^f
\end{equation}

where $ w^f $ is the final value of the weight after training and $ w^i $ its randomly chosen initial value. Rather than removing every weight and calculating the errors directly, the author approximates $ S $ by monitoring the sum of all the changes experienced by the weight during training. The estimated sensitivity is

\begin{equation}
\hat{S_{ij}} = \displaystyle{\sum_{n=0}^{N-1} \left[\Delta w_{ij} (n)\right]^2 \frac{w_{ij}^f}{\eta \cdot (w_{ij}^f - w_{ij}^i)}}
\end{equation}

The $ \Delta w $ values are calculated by backpropagation, hence, each weight has an estimated sensitivity after training. The lowest sensitivity weights are then deleted.

\subsection*{Contribution of This Work} \label{ssec:contribution_of_this_work}
We introduce own measure for the determination of how important individual synapses are. It is believed to work equally well or better than the others, while the principle is based on a nice and simple idea. It leads to a better performance in terms of computational demands, which is discussed and compared to the other listed methods in \cref{chap:discussion}.

Moreover, this study also suggests some ideas of how to take the advantages of pruned networks. We show on several examples, that the developed PA is capable of: 1) finding a minimal network structure for a given classification problem; 2) detection of feature importance; 3) distinguishing important samples from less important ones; 4) basic feature selection; 5) partial demystification of complicated networks.

\section{Master Thesis Objectives} \label{sec:thesis_objectives}
The objectives of this study are:

\begin{enumerate}
\item to design a neural network framework capable of learning a general classification problem;
\item to develop a pruning proceeder equipped by a tool for dimensionality reduction after pruning;
\item to demonstrate the developed methods on appropriate examples and suggest possible applications for pruned networks;
\item to implement state-of-the-art pruning methods and compare them to the developed method.
\end{enumerate}

\section{Thesis Outline} \label{sec:thesis_outline}
The thesis consists of 5 chapters following the standard skeleton of scientific publications. Chapter \ref{chap:methods} details the instruments and operations we performed. 

At first, in \cref{sec:classification_method} we give a general description of the used classification method and highlight some important design choices and conventions (a detailed description of the established conventions is then given in \cref{app:implementation}). 

Then the developed network pruning algorithm is introduced in \cref{sec:network_pruning}, which also contains the recipe of how to reduce the dimensionality of weight matrices after pruning. Then we put a section called "Insight of Neural Network" containing some ideas of how to use a derived minimal structure to understand the workflow in the network. Section \ref{sec:speech_data_gathering} is also included among the methods, because it describes the approach of how the speech data was collected.

In \cref{chap:examples}, six examples are presented. Each of the examples shows the pruning algorithm from a different point of view and each basically finds a new application for it.

Chapter \ref{chap:discussion} comes with the discussion about the results. It also contains a comparison of the developed pruning method to the presented state-of-the-art methods from \cref{sec:state_of_the_art}. Then, ideas for the future work are suggested. The study is concluded in \cref{chap:conclusion}.

As mentioned above, appendix \ref{app:implementation} gives a detailed view on the mathematical notation used in \cref{sec:classification_method}. Appendix \ref{app:supplementary_data} contains figures and tables that did not fit to the main text, but still can be interesting for some readers. Then, the structure of the workspace is provided in \cref{app:structure_of_the_workspace} and the attached code is documented in \cref{app:code_documentation}.