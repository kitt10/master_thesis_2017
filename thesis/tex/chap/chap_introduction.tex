\chapter{Introduction} \label{chap:introduction}
Introduction text...

\citep{sietsma:why_and_how}
The group of classification methods applicable in supervised machine learning systems is wide. To list some commonly known methods, we can use \textit{Support Vector Machines (SVMs)}, \textit{Decision trees}, probability-based \textit{Bayes classifiers} or archaic but still effective \textit{k-Nearest Neighbours}. Yet, neural networks are frequently prefered to the others and take the state-of-the-art part in many domains. Clearly it is due to their great performance. 

When we deal with a real problem (e.g. in industry), one often comes to the point when his or her network works well (let's say with accuracy of $ 90\% $), but a customer asks for a performance of $ 98\% $ for example. Then we encounter the problem when we need to know what is 

\newpage
\section{State of the Art} \label{sec:state_of_the_art}
In this work, we focus on the optimization of a feedforward neural network with a goal of understanding its overall functionality, which could possibly lead to a general knowledge of how to design networks and tailor them for a challenged problem.

Optimization is a wide term. In \citep{orhan:symmetry}, they try to break symmetries in a network in order to improve its performance. They do it by adding so-called "skip connections", which can also be considered as a kind of optimization.

In this study we rather focus on making networks small and simple. Having the smallest model that perfectly fits the classified data has two crucial advantages: 1) good generalization; 2) a good chance that we will understand how the model works.

There are two ways of how to end up with a small model that fits the data:

\begin{enumerate}
\item build a network from scratch by adding single parts (neurons, synapses) until a required performance is reached;
\item train a network that is larger than necessary and then remove the parts that are not needed.
\end{enumerate}

The first approach is left out for the future work, and we focus on the second course of action, which is called network \textit{pruning}. The general approach of a pruning procedure consists of these steps:

\begin{enumerate}
\item choose an oversized network architecture;
\item train the network until a reasonable solution is obtained;
\item delete a network part (synapse or neuron);
\item if the classification error has not grown go to step 2), otherwise finish.
\end{enumerate}

The key question is how to identify the parts that can be deleted without an error growth. A good survey of published pruning methods is done by \citep{reed:pa_survey}. The author starts with some hypothetical calculations of what would happen if we use a brute force and remove the elements one by one. It ends up with a complexity of $ O(MW^3) $, where $ M $ is the number of samples and $ W $ is the number of network elements - slow for large networks. 

The pruning methods described below take a less direct approach and they basically differ one from each other in how they identify the unimportant network parts. In \citep{reed:pa_survey}, he splits the methods into two groups:
\begin{itemize}
\item \textit{sensitivity calculation methods};

These methods estimate the sensitivity of the error function to removal of an element; the elements with the least effect can then be removed.
 
\item \textit{penalty-term methods}.

These methods modify the cost function so that backpropagation based on the function drives unnecessary parameters zero and, in effect, removes them during training.
\end{itemize}

Since the cost function could include sensitivity terms, there is some overlap in these groups and as the developed method would fit better to the first group, we focus on three published methods based on sensitivity calculations.

\subsection*{Skeletonization} \label{ssec:skeletonization}
In \citep{mozer:skeletonization} they introduce a measure called relevance $ \rho $ of a unit, which is an error when the unit is removed minus the error when the unit is left in place.

The value is approximated using a gating term $ \alpha $ for each unit such that

\begin{equation}
o_j = f(\displaystyle{\sum_i w_{ji} \cdot \alpha_i \cdot o_i})
\end{equation}

where $ o_j $ is the activity of unit $ j $, $ w_{ji} $ is the weight from neuron $ i $ to neuron $ j $ and $ f(\cdot) $ is the \textit{Sigmoid} function. If $ \alpha = 0 $, the unit has no influence on the network; if $ \alpha = 1 $, the unit behaves normally. The relevance estimation is then given by the derivative from backpropagation

\begin{equation}
\hat{\rho_i} = - \left.\frac{\partial E^l}{\partial \alpha_i}\right\rvert_{\alpha_i = 1}
\end{equation}

Rather than the usual sum of squared errors, the error $ E^l $ (\cref{eq:skeletonization_error}) is used to measure relevance, bacause it works better when the error is small.

\begin{equation} \label{eq:skeletonization_error}
E^l = \sum |t_{pj} - o_{pj}|
\end{equation}

The authors claim the method works well for understanding the behaviour of a network in terms of "rules", which is shown on the RPE problem and on Michalski's trains (both these examples are also adopted in this study for comparison).

\subsection*{Optimal Brain Damage} \label{ssec:optimal_brain_damage}
In \citep{lecun:obd} they use this ambitious title for a study that also tries to identify the unimportant weights and remove them from a network. Their measure is called "saliency" of a weight and it is estimated by the second derivative of the error with respect to the weight.

They compute the Hessian matrix $ H $ containing elements $ h_{ij} $.

\begin{equation}
h_{ij} = \frac{\partial^2 E}{\partial w_i \partial w_j}
\end{equation}

Since H is a very large matrix, they make a simplifying assumption that the off-diagonal terms of $ H $ are zero. This leaves

\begin{equation}
\delta E \approx \frac{1}{2} \displaystyle{\sum_i h_{ii} \cdot \delta \cdot w_i^2}
\end{equation}

It turns out that the second derivatives $ h_{kk} $ can be calculated by a modified back-propagation rule. The "saliency" $ s_k $ of weight $ w_k $ is then

\begin{equation}
s_k = h_{kk} \cdot \frac{w_k^2}{2}
\end{equation}

In each pruning step, weights with low saliencies are deleted. The method is tested on the MNIST dataset \citep{lecun:mnist}, which is also used to show the developed method in this study.

\subsection*{Karnin's Measure} \label{ssec:karnins_measure}
The measure published in \citep{karnin:pa} is the most similar to the one used by the developed PA. The author also used the change in weight during the pruning process to compute a measure called "sensitivity" for each synapse. The sensitivity $ S_{ij} $ of weight $ w_{ij} $ is given as

\begin{equation}
S_{ij} = - \frac{E(w^f) - E(w^i)}{w^f - w^i} \cdot w^f
\end{equation}

where $ w^f $ is the final value of the weight after training and $ w^i $ its randomly chosen initial value. Rather than removing every weight and calculating the errors directly, the author approximates $ S $ by monitoring the sum of all the changes experienced by the weight during training. The estimated sensitivity is

\begin{equation}
\hat{S_{ij}} = \displaystyle{\sum_{n=0}^{N-1} \left[\Delta w_{ij} (n)\right]^2 \frac{w_{ij}^f}{\eta \cdot (w_{ij}^f - w_{ij}^i)}}
\end{equation}

The $ \Delta w $ values are calculated by backpropagation, hence, each weight has an estimated sensitivity after training. The lowest sensitivity weights are then deleted.

\subsection*{Contribution of This Work} \label{ssec:contribution_of_this_work}
We introduce own measure for the determination of how important individual synapses are. It is believed to work equally well or better than the others, while the principle is based on a nice simple idea. It leads to a better performance in terms of computational demands, which is discussed and compared the other listed methods in \cref{chap:discussion}.

Moreover, this study also suggests some ideas of how to take the advantages of pruned networks.

\section{Mater Thesis Objectives} \label{sec:thesis_objectives}
Thesis objectives text...

\section{Thesis Outline} \label{sec:thesis_outline}
The thesis consists of 5 chapters following the standard skeleton of scientific publications. Chapter \ref{chap:methods} describes the methodology used in the study. At first, in \cref{sec:classification_method} we give a general description of the used classification method and highlight some important design choices and conventions (a detailed description of the established conventions is then put in \cref{app:implementation}). Then the developed network pruning algorithm is introduced in \cref{sec:network_pruning}, which also contains the recipe of how to reduce weight dimensionality after pruning. Then we put a section called "Insight of Neural Network" containing some ideas of how to use pruned networks. \cref{sec:speech_data_gathering} is also included among the methods, because it describes the approach of how the speech data was collected.

In \cref{chap:examples}, six examples are presented. Each of the examples shows the pruning algorithm from a different point of view and basically each finds a new application for it.

\cref{chap:discussion} comes with the discussion about the results. It also contains a comparison of the developed pruning method to the presented state-of-the-art-methods from \cref{sec:state_of_the_art}. Some ideas for the future work are also suggested. The study is then concluded in \cref{chap:conclusion}.

Appendix \ref{app:supplementary_data} contains figures and tables that did not fit to the main text, but still can be interesting for some readers. Then, the structure of the workspace is provided in \cref{app:structure_of_the_workspace} and the attached code is documented in \cref{app:code_documentation}.