{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### kitt_net neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kitt_net import FeedForwardNet\n",
    "from shelve import open as open_shelve\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from matplotlib import pyplot as plt, rcParams as mpl_params\n",
    "%matplotlib qt\n",
    "mpl_params['axes.labelsize'] = 28\n",
    "mpl_params['xtick.labelsize'] = 28\n",
    "mpl_params['ytick.labelsize'] = 28\n",
    "mpl_params['legend.fontsize'] = 30\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#net.load('../examples/speech/net_speech_500.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = open_shelve('../examples/karnin/dataset_karnin.ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Running job 0\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Network initialized.\u001b[0m\n",
      "\u001b[34m\t% problem dimension: \u001b[0m2\n",
      "\u001b[34m\t% number of classes: \u001b[0m2\n",
      "\u001b[34m\t% class labels: \u001b[0m[0.0, 1.0]\n",
      "\u001b[34m\t% net structure: \u001b[0m[2, 2, 2]\n",
      "\u001b[34m\t% net transfer function: \u001b[0mSigmoid\n",
      "----- Running job 1\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Network initialized.\u001b[0m\n",
      "\u001b[34m\t% problem dimension: \u001b[0m2\n",
      "\u001b[34m\t% number of classes: \u001b[0m2\n",
      "\u001b[34m\t% class labels: \u001b[0m[0.0, 1.0]\n",
      "\u001b[34m\t% net structure: \u001b[0m[2, 2, 2]\n",
      "\u001b[34m\t% net transfer function: \u001b[0mSigmoid\n",
      "----- Running job 2\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Network initialized.\u001b[0m\n",
      "\u001b[34m\t% problem dimension: \u001b[0m2\n",
      "\u001b[34m\t% number of classes: \u001b[0m2\n",
      "\u001b[34m\t% class labels: \u001b[0m[0.0, 1.0]\n",
      "\u001b[34m\t% net structure: \u001b[0m[2, 2, 2]\n",
      "\u001b[34m\t% net transfer function: \u001b[0mSigmoid\n",
      "----- Running job 3\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Network initialized.\u001b[0m\n",
      "\u001b[34m\t% problem dimension: \u001b[0m2\n",
      "\u001b[34m\t% number of classes: \u001b[0m2\n",
      "\u001b[34m\t% class labels: \u001b[0m[0.0, 1.0]\n",
      "\u001b[34m\t% net structure: \u001b[0m[2, 2, 2]\n",
      "\u001b[34m\t% net transfer function: \u001b[0mSigmoid\n",
      "----- Running job 4\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Network initialized.\u001b[0m\n",
      "\u001b[34m\t% problem dimension: \u001b[0m2\n",
      "\u001b[34m\t% number of classes: \u001b[0m2\n",
      "\u001b[34m\t% class labels: \u001b[0m[0.0, 1.0]\n",
      "\u001b[34m\t% net structure: \u001b[0m[2, 2, 2]\n",
      "\u001b[34m\t% net transfer function: \u001b[0mSigmoid\n",
      "28.2253368843 19.625273386\n",
      "25.3730963849 15.8923056229\n",
      "27.0873077587 18.3364118912\n",
      "27.7173556858 20.7860758927\n",
      "28.0590498989 18.2387667704\n",
      "28.8696458098 0.180338050227\n",
      "26.7005593742 16.0204382385\n",
      "0.837986346799 0.898078642004\n",
      "0.760381446017 0.534862295924\n",
      "0.542078086184 0.0134845025837\n",
      "[-3.61169097] [ 17.07057827]\n",
      "[-2.8400067] [-13.57098692]\n",
      "[ 2.80882583] [ 16.66201024]\n",
      "[ 2.96458785] [ 16.55231949]\n",
      "[ 3.19651507] [ 16.3838973]\n"
     ]
    }
   ],
   "source": [
    "f1 = list()\n",
    "f2 = list()\n",
    "w1 = list()\n",
    "w2 = list()\n",
    "b1 = list()\n",
    "b2 = list()\n",
    "n_obs = 5\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "n_other = 0\n",
    "for job in range(n_obs):\n",
    "    print '----- Running job', job\n",
    "    net = FeedForwardNet(hidden=[2], tf_name='Sigmoid')\n",
    "    net.fit(x=dataset['x'], y=dataset['y'], x_val=dataset['x_val'], y_val=dataset['y_val'], \n",
    "            learning_rate=0.7, n_epoch=50, req_err=0.0, batch_size=1, nd_der=False, verbose=False)\n",
    "    #net.prune(req_acc=0.98, req_err=0.05, n_epoch=50, retrain=True, measure='kitt', levels=(10, 7, 5, 3, 2, 1, 0), verbose=False)\n",
    "    changes0 = abs(net.w[0]-net.w_init[0])\n",
    "    f1.append(max(changes0[:,0]))\n",
    "    f2.append(max(changes0[:,1]))\n",
    "    ind1 = np.argmax(abs(net.w[0][:,0]))\n",
    "    ind2 = np.argmax(abs(net.w[0][:,1]))\n",
    "    w1.append(net.w[0][ind1,0])\n",
    "    w2.append(net.w[0][ind2,1])\n",
    "    \n",
    "    if np.argmax(changes0[:,0]) == 0:\n",
    "        b1.append(net.b[0][0])\n",
    "        b2.append(net.b[0][1])\n",
    "    else:\n",
    "        b1.append(net.b[0][1])\n",
    "        b2.append(net.b[0][0])\n",
    "    \n",
    "    if net.w_is[0][0,0] and net.w_is[0][1,1] and not net.w_is[0][0,1] and not net.w_is[0][1,0]:\n",
    "        n1 += 1\n",
    "    elif net.w_is[0][0,1] and net.w_is[0][1,0] and not net.w_is[0][0,0] and not net.w_is[0][1,1]:\n",
    "        n2 += 1\n",
    "    else:\n",
    "        n_other += 1\n",
    "    \n",
    "for f1_, f2_ in zip(f1, f2):\n",
    "    if f1_ < f2_:\n",
    "        print f1_, f2_, 'MISTAKE'\n",
    "    else:\n",
    "        print f1_, f2_\n",
    "\n",
    "for w1_, w2_ in zip(w1, w2):\n",
    "    print w1_, w2_\n",
    "        \n",
    "for b1_, b2_ in zip(b1, b2):\n",
    "    print b1_, b2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = 'pruning result 1', 'pruning result 2', 'other'\n",
    "sizes = [n1, n2, n_other]\n",
    "colors = ['darkblue', 'darkgreen', 'maroon']\n",
    "explode = (0, 0, 0.1)\n",
    "patches, _, texts = plt.pie(sizes, explode=explode, colors=colors, shadow=True, startangle=140,\n",
    "                    autopct = '%1.0f%%')\n",
    "texts[0].set_fontsize(35)\n",
    "texts[1].set_fontsize(35)\n",
    "texts[2].set_fontsize(35)\n",
    "plt.legend(patches, labels, loc=\"lower right\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "medianprops = dict(linestyle='-', linewidth=3, color='black')\n",
    "meanpointprops = dict(marker='D', markeredgecolor='black',\n",
    "                      markerfacecolor='black')\n",
    "boxes = plt.boxplot([f1, f2], widths=[0.75]*2, positions=range(2), patch_artist=True, medianprops=medianprops,\n",
    "                    meanprops=meanpointprops, showmeans=True)\n",
    "\n",
    "for box in boxes['boxes']:\n",
    "    box.set_facecolor('darkblue')\n",
    "    box.set_color('darkblue')\n",
    "\n",
    "plt.xlim([-0.5, 1.5])\n",
    "plt.xticks(range(2), ('from $ x_1 $', 'from $ x_2 $'))\n",
    "plt.xlabel('synapses')\n",
    "plt.ylabel('weight change in training')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Learning has started...\u001b[0m\n",
      "\u001b[34m\t% problem dimension: \u001b[0m2\n",
      "\u001b[34m\t% number of training samples: \u001b[0m1600\n",
      "\u001b[34m\t% number of validation samples: \u001b[0m200\n",
      "\u001b[34m\t% learning rate: \u001b[0m0.07\n",
      "\u001b[34m\t% mini-batch size: \u001b[0m1\n",
      "\u001b[34m\t% maximum number of epochs (t.c.): \u001b[0m50\n",
      "\u001b[34m\t% maximum number of stable epochs (t.c.): \u001b[0minf\n",
      "\u001b[34m\t% required accuracy (t.c.): \u001b[0minf\n",
      "\u001b[34m\t% required error (t.c.): \u001b[0m0.0\n",
      "\n",
      "\n",
      "epoch   on training data      on validation data       epoch time          \n",
      "-------------------------------------------------------------------\n",
      " 1\t  \u001b[32m0.99\u001b[0m/\u001b[31m0.0025\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0040\u001b[0m\t\t\u001b[36m0.3053 s\u001b[0m\n",
      " 2\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0035\u001b[0m\t\t\u001b[36m0.2530 s\u001b[0m\n",
      " 3\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[31m0.0030\u001b[0m\t\t\u001b[36m0.2617 s\u001b[0m\n",
      " 4\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[31m0.0029\u001b[0m\t\t\u001b[36m0.3999 s\u001b[0m\n",
      " 5\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0030\u001b[0m\t\t\u001b[36m0.2490 s\u001b[0m\n",
      " 6\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[31m0.0029\u001b[0m\t\t\u001b[36m0.2592 s\u001b[0m\n",
      " 7\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0030\u001b[0m\t\t\u001b[36m0.2614 s\u001b[0m\n",
      " 8\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[31m0.0027\u001b[0m\t\t\u001b[36m0.2626 s\u001b[0m\n",
      " 9\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0030\u001b[0m\t\t\u001b[36m0.2659 s\u001b[0m\n",
      " 10\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2427 s\u001b[0m\n",
      " 11\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2509 s\u001b[0m\n",
      " 12\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0027\u001b[0m\t\t\u001b[36m0.2509 s\u001b[0m\n",
      " 13\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2466 s\u001b[0m\n",
      " 14\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0030\u001b[0m\t\t\u001b[36m0.2520 s\u001b[0m\n",
      " 15\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0031\u001b[0m\t\t\u001b[36m0.2563 s\u001b[0m\n",
      " 16\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2481 s\u001b[0m\n",
      " 17\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0024\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2639 s\u001b[0m\n",
      " 18\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0030\u001b[0m\t\t\u001b[36m0.3888 s\u001b[0m\n",
      " 19\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2550 s\u001b[0m\n",
      " 20\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0030\u001b[0m\t\t\u001b[36m0.3116 s\u001b[0m\n",
      " 21\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2457 s\u001b[0m\n",
      " 22\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0024\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2416 s\u001b[0m\n",
      " 23\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2475 s\u001b[0m\n",
      " 24\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2552 s\u001b[0m\n",
      " 25\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.3282 s\u001b[0m\n",
      " 26\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.3700 s\u001b[0m\n",
      " 27\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0027\u001b[0m\t\t\u001b[36m0.2514 s\u001b[0m\n",
      " 28\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0031\u001b[0m\t\t\u001b[36m0.2573 s\u001b[0m\n",
      " 29\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2604 s\u001b[0m\n",
      " 30\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2545 s\u001b[0m\n",
      " 31\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2507 s\u001b[0m\n",
      " 32\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0030\u001b[0m\t\t\u001b[36m0.2503 s\u001b[0m\n",
      " 33\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0031\u001b[0m\t\t\u001b[36m0.2596 s\u001b[0m\n",
      " 34\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[31m0.0027\u001b[0m\t\t\u001b[36m0.2671 s\u001b[0m\n",
      " 35\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0031\u001b[0m\t\t\u001b[36m0.2509 s\u001b[0m\n",
      " 36\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2604 s\u001b[0m\n",
      " 37\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2535 s\u001b[0m\n",
      " 38\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2455 s\u001b[0m\n",
      " 39\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.3668 s\u001b[0m\n",
      " 40\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.3418 s\u001b[0m\n",
      " 41\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2544 s\u001b[0m\n",
      " 42\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2456 s\u001b[0m\n",
      " 43\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2558 s\u001b[0m\n",
      " 44\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[31m0.0026\u001b[0m\t\t\u001b[36m0.2563 s\u001b[0m\n",
      " 45\t  \u001b[32m1.00\u001b[0m/\u001b[31m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0029\u001b[0m\t\t\u001b[36m0.2489 s\u001b[0m\n",
      " 46\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0028\u001b[0m\t\t\u001b[36m0.2551 s\u001b[0m\n",
      " 47\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0031\u001b[0m\t\t\u001b[36m0.3729 s\u001b[0m\n",
      " 48\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0023\u001b[0m\u001b[32m\t\t0.99\u001b[0m/\u001b[35m0.0033\u001b[0m\t\t\u001b[36m0.3430 s\u001b[0m\n",
      " 49\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0027\u001b[0m\t\t\u001b[36m0.2656 s\u001b[0m\n",
      " 50\t  \u001b[32m1.00\u001b[0m/\u001b[35m0.0022\u001b[0m\u001b[32m\t\t1.00\u001b[0m/\u001b[35m0.0027\u001b[0m\t\t\u001b[36m0.2396 s\u001b[0m\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Learning finished in 28.0054s. Given number of epochs performed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "net.learning.kw['learning_rate'] = 0.07\n",
    "net.learning.learn_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Pruning has started...\u001b[0m\n",
      "\u001b[34m\t% net initial structure: \u001b[0m[2, 2, 2]\n",
      "\u001b[34m\t% net initial number of synapses (w, b): \u001b[0m(8, 4)\n",
      "\u001b[34m\t% min required accuracy (s.c.): \u001b[0m0.98\n",
      "\u001b[34m\t% max required error (s.c.): \u001b[0m0.05\n",
      "\u001b[34m\t% maximum number of re-training epochs (gu.c.): \u001b[0m50\n",
      "\u001b[34m\t% number of stable iterations (gu.c.): \u001b[0m10\n",
      "\n",
      "\n",
      "step    trying to cut     structure           left synapses (w/b)    retrained      next level     step time      \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\u001b[33m0       0                 [2, 2, 2]           (8, 4)                 None           75             \u001b[36mNone\u001b[0m  \u001b[0m\n",
      "\u001b[31m1       6                 [2, 0, 2]           (0, 2)                 no             50             \u001b[36m10.4551 s\u001b[0m\u001b[0m\n",
      "\u001b[31m2       4                 [2, 1, 2]           (3, 3)                 no             35             \u001b[36m10.2706 s\u001b[0m\u001b[0m\n",
      "\u001b[31m3       3                 [2, 1, 2]           (3, 3)                 no             20             \u001b[36m9.6648 s\u001b[0m\u001b[0m\n",
      "\u001b[32m4       2                 [2, 2, 2]           (6, 4)                 yes            20             \u001b[36m0.8287 s\u001b[0m\u001b[0m\n",
      "\u001b[31m5       2                 [2, 1, 2]           (3, 3)                 no             10             \u001b[36m9.6779 s\u001b[0m\u001b[0m\n",
      "\u001b[31m6       1                 [2, 1, 2]           (3, 3)                 no             10             \u001b[36m9.6347 s\u001b[0m\u001b[0m\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Pruning finished in 50.5317809582 s.\u001b[0m\n",
      "\u001b[34m\t% net final structure: \u001b[0m[2, 2, 2]\n",
      "\u001b[34m\t% net final number of synapses (w/b): \u001b[0m(6, 4)\n",
      "\u001b[34m\t% classification accuracy on training data: \u001b[0m0.9875\n",
      "\u001b[34m\t% classification error on training data: \u001b[0m0.0201181461629\n",
      "\u001b[34m\t% classification accuracy on validation data: \u001b[0m0.985\n",
      "\u001b[34m\t% classification error on validation data: \u001b[0m0.0205679546841\n"
     ]
    }
   ],
   "source": [
    "net.prune(req_acc=0.98, req_err=0.05, n_epoch=50, retrain=True, measure='kitt', levels=(75, 50, 35, 20, 10, 7, 5, 3, 2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  0.]]\n",
      "[[ 0.  1.]\n",
      " [ 1.  1.]]\n",
      "---------------\n",
      "MAGNITUDE\n",
      "[[  0.4377715   25.7493453 ]\n",
      " [ 33.75905979   0.        ]]\n",
      "[[  0.          13.20460031]\n",
      " [ 10.66642297  13.29728159]]\n",
      "KITT\n",
      "[[  0.35082581  24.25222564]\n",
      " [ 32.46552466   1.22270583]]\n",
      "[[  0.23011079  13.14601023]\n",
      " [ 11.7394276   12.62665077]]\n",
      "OBD\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print net.w_is[0]\n",
    "print net.w_is[1]\n",
    "\n",
    "print '---------------'\n",
    "print 'MAGNITUDE'\n",
    "print abs(net.w[0])\n",
    "print abs(net.w[1])\n",
    "\n",
    "print 'KITT'\n",
    "print abs(net.w[0]-net.w_init[0])\n",
    "print abs(net.w[1]-net.w_init[1])\n",
    "\n",
    "'''\n",
    "print 'KARNIN'\n",
    "changes_ = [np.zeros(shape=w_i.shape) for w_i in net.w]\n",
    "for ep_i in range(net.dw_i):\n",
    "    for l_i in range(len(changes_)):\n",
    "        den = (net.learning.kw['learning_rate']*(net.w[l_i]-net.w_init[l_i]))\n",
    "        changes_[l_i] += net.dw_container[l_i][ep_i]**2*(net.w[l_i]/den)\n",
    "print changes_[0]\n",
    "print changes_[1]\n",
    "'''        \n",
    "print 'OBD'                    \n",
    "print net.saliency[0]\n",
    "print net.saliency[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net structure to be dumped: [784, 7, 2] | Number of synapses: (5502, 9)\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Net dumped as ../examples/mnist/net_mnist_4+9.net\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print 'Net structure to be dumped:', net.structure, '| Number of synapses:', net.count_synapses()\n",
    "net.dump('../examples/mnist/net_mnist_4+9.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.v_data = net.prepare_data(x=dataset['x_val'], y=dataset['y_val'])\n",
    "net.t_data = net.prepare_data(x=dataset['x'], y=dataset['y'])\n",
    "test_data = net.prepare_data(x=dataset['x_test'], y=dataset['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.442842269651\n",
      "[[ 0.542       0.002       0.          0.          0.          0.          0.002\n",
      "   0.028       0.          0.          0.          0.          0.004       0.01\n",
      "   0.          0.004       0.264       0.014       0.          0.          0.032\n",
      "   0.          0.          0.042       0.          0.          0.          0.004\n",
      "   0.022       0.          0.004       0.          0.002       0.          0.002\n",
      "   0.          0.002       0.          0.02        0.        ]\n",
      " [ 0.          0.466       0.          0.          0.          0.          0.\n",
      "   0.          0.02        0.004       0.092       0.          0.          0.\n",
      "   0.022       0.11        0.016       0.          0.048       0.          0.006\n",
      "   0.018       0.          0.004       0.          0.          0.006       0.\n",
      "   0.          0.          0.          0.024       0.          0.034       0.104\n",
      "   0.          0.          0.026       0.          0.        ]\n",
      " [ 0.002079    0.00831601  0.65280665  0.          0.          0.\n",
      "   0.01871102  0.01663202  0.002079    0.03118503  0.          0.\n",
      "   0.01039501  0.004158    0.02702703  0.002079    0.          0.04781705\n",
      "   0.002079    0.03534304  0.002079    0.          0.02910603  0.          0.\n",
      "   0.          0.00831601  0.004158    0.01039501  0.03326403  0.00831601\n",
      "   0.          0.004158    0.          0.00831601  0.          0.00831601\n",
      "   0.          0.          0.02286902]\n",
      " [ 0.09        0.002       0.          0.002       0.          0.          0.004\n",
      "   0.03        0.          0.002       0.          0.          0.002       0.006\n",
      "   0.002       0.008       0.18        0.          0.          0.002       0.436\n",
      "   0.006       0.016       0.006       0.          0.          0.          0.016\n",
      "   0.004       0.002       0.01        0.002       0.15        0.          0.002\n",
      "   0.          0.          0.          0.018       0.002     ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.02040816  0.          0.          0.          0.          0.          0.\n",
      "   0.04081633  0.          0.          0.04081633  0.          0.          0.\n",
      "   0.08163265  0.          0.          0.04081633  0.          0.          0.\n",
      "   0.04081633  0.          0.          0.08163265  0.          0.          0.\n",
      "   0.          0.          0.04081633  0.04081633  0.42857143  0.14285714]\n",
      " [ 0.018       0.008       0.032       0.002       0.          0.          0.376\n",
      "   0.096       0.          0.022       0.002       0.          0.008       0.006\n",
      "   0.13        0.002       0.028       0.034       0.002       0.004       0.024\n",
      "   0.002       0.016       0.008       0.          0.          0.002       0.004\n",
      "   0.02        0.014       0.002       0.002       0.01        0.          0.018\n",
      "   0.          0.008       0.012       0.088       0.        ]\n",
      " [ 0.012       0.          0.044       0.          0.          0.          0.444\n",
      "   0.094       0.          0.          0.          0.          0.05        0.\n",
      "   0.          0.          0.018       0.01        0.          0.004       0.024\n",
      "   0.          0.038       0.014       0.          0.          0.          0.032\n",
      "   0.076       0.068       0.014       0.          0.016       0.          0.002\n",
      "   0.          0.024       0.          0.008       0.008     ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.02242152  0.71076233  0.          0.          0.          0.\n",
      "   0.0044843   0.02690583  0.01121076  0.          0.01121076  0.01345291\n",
      "   0.          0.          0.0044843   0.          0.00672646  0.          0.\n",
      "   0.          0.          0.00896861  0.08744395  0.01793722  0.          0.\n",
      "   0.01793722  0.          0.0044843   0.          0.00224215  0.\n",
      "   0.01121076  0.03811659]\n",
      " [ 0.          0.04        0.006       0.          0.          0.          0.\n",
      "   0.          0.61        0.126       0.086       0.          0.          0.\n",
      "   0.014       0.002       0.002       0.          0.022       0.          0.\n",
      "   0.018       0.          0.006       0.          0.          0.002       0.\n",
      "   0.          0.          0.004       0.          0.002       0.032       0.004\n",
      "   0.          0.002       0.014       0.          0.008     ]\n",
      " [ 0.          0.00208768  0.00208768  0.          0.          0.          0.\n",
      "   0.00417537  0.08141962  0.66805846  0.02296451  0.          0.          0.\n",
      "   0.0960334   0.00208768  0.00417537  0.          0.00208768  0.\n",
      "   0.00208768  0.01670146  0.          0.01461378  0.          0.          0.\n",
      "   0.00208768  0.00208768  0.          0.          0.          0.00626305\n",
      "   0.01461378  0.          0.          0.00208768  0.00208768  0.00208768\n",
      "   0.05010438]\n",
      " [ 0.          0.092       0.          0.          0.          0.          0.\n",
      "   0.          0.032       0.022       0.626       0.          0.          0.\n",
      "   0.062       0.012       0.012       0.          0.012       0.          0.002\n",
      "   0.016       0.          0.002       0.          0.          0.01        0.\n",
      "   0.          0.          0.          0.018       0.          0.062       0.014\n",
      "   0.          0.          0.006       0.          0.        ]\n",
      " [ 0.          0.162       0.074       0.          0.          0.          0.\n",
      "   0.          0.068       0.02        0.008       0.          0.          0.\n",
      "   0.048       0.026       0.002       0.          0.072       0.          0.\n",
      "   0.012       0.          0.01        0.          0.          0.142       0.006\n",
      "   0.          0.002       0.          0.016       0.004       0.006       0.212\n",
      "   0.          0.006       0.07        0.          0.034     ]\n",
      " [ 0.008       0.          0.004       0.          0.          0.          0.004\n",
      "   0.004       0.002       0.          0.          0.          0.672       0.002\n",
      "   0.002       0.028       0.03        0.022       0.          0.          0.\n",
      "   0.004       0.          0.          0.          0.          0.002       0.006\n",
      "   0.004       0.01        0.022       0.          0.          0.          0.014\n",
      "   0.          0.006       0.          0.142       0.012     ]\n",
      " [ 0.12455516  0.          0.          0.          0.          0.\n",
      "   0.00355872  0.04626335  0.          0.          0.          0.\n",
      "   0.03202847  0.25978648  0.          0.          0.08540925  0.          0.\n",
      "   0.          0.02135231  0.          0.          0.06049822  0.          0.\n",
      "   0.          0.02135231  0.          0.          0.113879    0.01067616\n",
      "   0.01423488  0.          0.00355872  0.          0.01067616  0.\n",
      "   0.19217082  0.        ]\n",
      " [ 0.          0.04008439  0.02531646  0.          0.          0.\n",
      "   0.01265823  0.00421941  0.00421941  0.07805907  0.08227848  0.          0.\n",
      "   0.          0.62025316  0.          0.          0.00421941  0.\n",
      "   0.0021097   0.          0.          0.          0.01265823  0.          0.\n",
      "   0.00843882  0.          0.          0.00843882  0.          0.01054852\n",
      "   0.0021097   0.04852321  0.0021097   0.          0.00421941  0.00632911\n",
      "   0.          0.02320675]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.79        0.002       0.          0.014       0.          0.\n",
      "   0.012       0.          0.004       0.          0.          0.006       0.\n",
      "   0.          0.          0.          0.092       0.          0.01        0.06\n",
      "   0.          0.          0.008       0.          0.002     ]\n",
      " [ 0.174       0.          0.004       0.          0.          0.          0.008\n",
      "   0.014       0.          0.          0.          0.          0.006       0.014\n",
      "   0.          0.02        0.478       0.002       0.          0.          0.054\n",
      "   0.008       0.          0.014       0.          0.          0.002       0.002\n",
      "   0.          0.          0.058       0.02        0.064       0.          0.012\n",
      "   0.          0.004       0.002       0.04        0.        ]\n",
      " [ 0.          0.          0.048       0.          0.          0.          0.014\n",
      "   0.002       0.          0.          0.          0.          0.004       0.\n",
      "   0.          0.008       0.          0.8         0.          0.038       0.\n",
      "   0.          0.008       0.          0.          0.          0.          0.\n",
      "   0.018       0.036       0.002       0.          0.          0.          0.\n",
      "   0.          0.014       0.          0.          0.008     ]\n",
      " [ 0.          0.036       0.002       0.          0.          0.          0.\n",
      "   0.02        0.03        0.004       0.002       0.          0.          0.\n",
      "   0.002       0.002       0.004       0.          0.706       0.          0.\n",
      "   0.018       0.002       0.004       0.          0.          0.008       0.\n",
      "   0.          0.          0.          0.014       0.          0.078       0.042\n",
      "   0.          0.          0.002       0.          0.024     ]\n",
      " [ 0.          0.          0.086       0.          0.          0.          0.008\n",
      "   0.016       0.          0.          0.          0.          0.006       0.002\n",
      "   0.01        0.014       0.04        0.318       0.          0.238       0.018\n",
      "   0.          0.072       0.004       0.          0.          0.002       0.008\n",
      "   0.016       0.03        0.008       0.016       0.028       0.          0.016\n",
      "   0.          0.022       0.002       0.          0.02      ]\n",
      " [ 0.046       0.002       0.          0.          0.          0.          0.004\n",
      "   0.04        0.          0.          0.          0.          0.008       0.006\n",
      "   0.006       0.006       0.232       0.002       0.          0.          0.362\n",
      "   0.          0.012       0.012       0.          0.          0.          0.012\n",
      "   0.006       0.006       0.078       0.012       0.096       0.004       0.008\n",
      "   0.          0.          0.014       0.012       0.014     ]\n",
      " [ 0.004       0.02        0.          0.          0.          0.          0.\n",
      "   0.004       0.024       0.008       0.054       0.          0.          0.\n",
      "   0.002       0.038       0.014       0.          0.08        0.002       0.\n",
      "   0.446       0.          0.032       0.          0.          0.02        0.\n",
      "   0.          0.          0.          0.024       0.012       0.078       0.046\n",
      "   0.          0.014       0.056       0.          0.022     ]\n",
      " [ 0.          0.          0.094       0.          0.          0.          0.012\n",
      "   0.056       0.01        0.006       0.          0.          0.          0.002\n",
      "   0.056       0.          0.006       0.068       0.004       0.026       0.076\n",
      "   0.002       0.322       0.004       0.          0.          0.028       0.002\n",
      "   0.024       0.014       0.03        0.018       0.09        0.          0.014\n",
      "   0.          0.012       0.002       0.002       0.02      ]\n",
      " [ 0.018       0.016       0.          0.          0.          0.          0.012\n",
      "   0.          0.004       0.006       0.004       0.          0.008       0.\n",
      "   0.018       0.022       0.016       0.006       0.          0.          0.008\n",
      "   0.          0.008       0.662       0.          0.          0.03        0.\n",
      "   0.018       0.006       0.014       0.04        0.022       0.          0.01\n",
      "   0.          0.022       0.024       0.004       0.002     ]\n",
      " [ 0.          0.          0.004       0.          0.          0.          0.062\n",
      "   0.208       0.          0.022       0.004       0.          0.008       0.01\n",
      "   0.06        0.002       0.03        0.014       0.004       0.002       0.132\n",
      "   0.002       0.072       0.          0.          0.          0.          0.036\n",
      "   0.066       0.016       0.096       0.01        0.06        0.          0.014\n",
      "   0.          0.004       0.          0.06        0.002     ]\n",
      " [ 0.004       0.002       0.178       0.          0.          0.          0.032\n",
      "   0.064       0.          0.014       0.          0.          0.002       0.\n",
      "   0.144       0.002       0.004       0.032       0.          0.03        0.072\n",
      "   0.002       0.034       0.012       0.          0.          0.018       0.054\n",
      "   0.048       0.06        0.032       0.028       0.09        0.          0.008\n",
      "   0.          0.018       0.004       0.002       0.01      ]\n",
      " [ 0.          0.016       0.          0.          0.          0.          0.\n",
      "   0.          0.002       0.          0.          0.          0.002       0.\n",
      "   0.006       0.064       0.006       0.002       0.008       0.          0.\n",
      "   0.012       0.016       0.034       0.          0.          0.428       0.002\n",
      "   0.          0.002       0.004       0.1         0.01        0.008       0.202\n",
      "   0.          0.          0.072       0.002       0.002     ]\n",
      " [ 0.066       0.          0.          0.          0.          0.          0.034\n",
      "   0.002       0.          0.          0.          0.          0.018       0.03\n",
      "   0.002       0.004       0.084       0.004       0.          0.006       0.04\n",
      "   0.002       0.          0.018       0.          0.          0.002       0.298\n",
      "   0.014       0.036       0.16        0.004       0.098       0.          0.004\n",
      "   0.          0.034       0.002       0.01        0.028     ]\n",
      " [ 0.028       0.          0.          0.          0.          0.          0.11\n",
      "   0.116       0.          0.          0.          0.          0.004       0.002\n",
      "   0.          0.          0.036       0.052       0.          0.006       0.014\n",
      "   0.          0.002       0.018       0.          0.          0.004       0.006\n",
      "   0.488       0.05        0.          0.002       0.01        0.          0.\n",
      "   0.          0.02        0.002       0.002       0.028     ]\n",
      " [ 0.026       0.          0.006       0.          0.          0.          0.028\n",
      "   0.158       0.          0.          0.          0.          0.008       0.008\n",
      "   0.012       0.          0.074       0.058       0.          0.006       0.032\n",
      "   0.          0.008       0.032       0.          0.          0.          0.012\n",
      "   0.108       0.27        0.02        0.014       0.064       0.          0.006\n",
      "   0.          0.036       0.          0.          0.014     ]\n",
      " [ 0.026       0.          0.          0.          0.          0.          0.\n",
      "   0.008       0.          0.          0.          0.          0.012       0.016\n",
      "   0.          0.          0.12        0.          0.          0.          0.046\n",
      "   0.          0.          0.004       0.          0.          0.002       0.006\n",
      "   0.006       0.          0.604       0.006       0.016       0.          0.016\n",
      "   0.          0.002       0.004       0.1         0.006     ]\n",
      " [ 0.          0.01        0.006       0.          0.          0.          0.002\n",
      "   0.002       0.          0.          0.          0.          0.002       0.\n",
      "   0.004       0.222       0.016       0.          0.002       0.012       0.002\n",
      "   0.004       0.004       0.006       0.          0.          0.074       0.006\n",
      "   0.          0.          0.002       0.464       0.006       0.          0.154\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.012       0.          0.004       0.          0.          0.          0.008\n",
      "   0.032       0.004       0.002       0.002       0.          0.01        0.\n",
      "   0.          0.002       0.09        0.014       0.          0.008       0.07\n",
      "   0.          0.002       0.022       0.          0.          0.01        0.008\n",
      "   0.016       0.01        0.036       0.012       0.56        0.          0.01\n",
      "   0.          0.022       0.01        0.002       0.022     ]\n",
      " [ 0.          0.02        0.          0.          0.          0.          0.\n",
      "   0.          0.024       0.008       0.05        0.          0.          0.\n",
      "   0.002       0.018       0.          0.          0.15        0.          0.\n",
      "   0.042       0.          0.006       0.          0.          0.022       0.\n",
      "   0.          0.          0.          0.01        0.          0.594       0.028\n",
      "   0.          0.          0.014       0.          0.012     ]\n",
      " [ 0.          0.018       0.          0.          0.          0.          0.\n",
      "   0.          0.002       0.          0.          0.          0.          0.\n",
      "   0.          0.086       0.006       0.          0.046       0.004       0.006\n",
      "   0.04        0.006       0.002       0.          0.          0.112       0.008\n",
      "   0.          0.          0.014       0.136       0.008       0.028       0.458\n",
      "   0.          0.002       0.016       0.          0.002     ]\n",
      " [ 0.022       0.002       0.          0.          0.          0.          0.018\n",
      "   0.052       0.          0.002       0.          0.          0.22        0.016\n",
      "   0.004       0.002       0.028       0.034       0.          0.004       0.014\n",
      "   0.002       0.006       0.008       0.          0.          0.008       0.022\n",
      "   0.01        0.02        0.238       0.008       0.046       0.          0.024\n",
      "   0.          0.026       0.002       0.152       0.01      ]\n",
      " [ 0.002       0.          0.068       0.          0.          0.          0.028\n",
      "   0.014       0.004       0.          0.          0.          0.016       0.002\n",
      "   0.004       0.004       0.046       0.122       0.008       0.016       0.012\n",
      "   0.          0.012       0.024       0.          0.          0.016       0.024\n",
      "   0.08        0.026       0.018       0.          0.02        0.01        0.006\n",
      "   0.          0.354       0.006       0.          0.058     ]\n",
      " [ 0.          0.094       0.          0.          0.          0.          0.\n",
      "   0.          0.018       0.          0.042       0.          0.          0.\n",
      "   0.01        0.008       0.016       0.002       0.022       0.          0.\n",
      "   0.07        0.006       0.034       0.          0.          0.032       0.002\n",
      "   0.          0.004       0.          0.024       0.012       0.054       0.03\n",
      "   0.          0.006       0.504       0.          0.01      ]\n",
      " [ 0.038       0.          0.          0.          0.          0.          0.008\n",
      "   0.006       0.          0.          0.          0.          0.108       0.068\n",
      "   0.          0.004       0.038       0.          0.          0.          0.\n",
      "   0.          0.002       0.004       0.          0.          0.          0.004\n",
      "   0.004       0.          0.178       0.          0.          0.          0.006\n",
      "   0.          0.028       0.          0.502       0.002     ]\n",
      " [ 0.          0.002       0.006       0.          0.          0.          0.01\n",
      "   0.036       0.012       0.018       0.          0.          0.          0.\n",
      "   0.004       0.          0.002       0.012       0.052       0.002       0.01\n",
      "   0.004       0.002       0.002       0.          0.          0.014       0.\n",
      "   0.006       0.012       0.          0.004       0.006       0.04        0.012\n",
      "   0.          0.012       0.002       0.03        0.688     ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = [net.predict(x)[0][0] for x, y in test_data]\n",
    "cm = confusion_matrix(y_true=dataset['y_test'], y_pred=predictions, labels=net.labels)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "labels = [label for label in net.labels if label in dataset['y_test']]\n",
    "plt.imshow(cm, aspect='auto', interpolation='none', vmin=0, vmax=1)\n",
    "plt.xticks(range(len(labels)), labels)\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print accuracy_score(y_true=dataset['y_test'], y_pred=predictions)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Learning has started...\u001b[0m\n",
      "\u001b[34m\t% problem dimension: \u001b[0m76\n",
      "\u001b[34m\t% number of training samples: \u001b[0m16000\n",
      "\u001b[34m\t% number of validation samples: \u001b[0m50\n",
      "\u001b[34m\t% learning rate: \u001b[0m0.001\n",
      "\u001b[34m\t% mini-batch size: \u001b[0m1\n",
      "\u001b[34m\t% maximum number of epochs (t.c.): \u001b[0m50\n",
      "\u001b[34m\t% maximum number of stable epochs (t.c.): \u001b[0m20\n",
      "\u001b[34m\t% required accuracy (t.c.): \u001b[0m1.0\n",
      "\u001b[34m\t% required error (t.c.): \u001b[0m-inf\n",
      "\n",
      "\n",
      "epoch   on training data      on validation data       epoch time          \n",
      "-------------------------------------------------------------------\n",
      " 1\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0046\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3610\u001b[0m\t\t\u001b[36m1.7048 s\u001b[0m\n",
      " 2\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0046\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3603\u001b[0m\t\t\u001b[36m1.6259 s\u001b[0m\n",
      " 3\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0046\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3597\u001b[0m\t\t\u001b[36m1.4826 s\u001b[0m\n",
      " 4\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0045\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3591\u001b[0m\t\t\u001b[36m1.5106 s\u001b[0m\n",
      " 5\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0045\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3585\u001b[0m\t\t\u001b[36m1.5079 s\u001b[0m\n",
      " 6\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0045\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3579\u001b[0m\t\t\u001b[36m1.5470 s\u001b[0m\n",
      " 7\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0045\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3574\u001b[0m\t\t\u001b[36m1.4907 s\u001b[0m\n",
      " 8\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0044\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3569\u001b[0m\t\t\u001b[36m1.5318 s\u001b[0m\n",
      " 9\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0044\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3564\u001b[0m\t\t\u001b[36m1.5330 s\u001b[0m\n",
      " 10\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0044\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3559\u001b[0m\t\t\u001b[36m1.6698 s\u001b[0m\n",
      " 11\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0044\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3555\u001b[0m\t\t\u001b[36m1.4969 s\u001b[0m\n",
      " 12\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0044\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3551\u001b[0m\t\t\u001b[36m1.5572 s\u001b[0m\n",
      " 13\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0044\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3547\u001b[0m\t\t\u001b[36m1.5034 s\u001b[0m\n",
      " 14\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0044\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3543\u001b[0m\t\t\u001b[36m1.6604 s\u001b[0m\n",
      " 15\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3539\u001b[0m\t\t\u001b[36m1.7190 s\u001b[0m\n",
      " 16\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3536\u001b[0m\t\t\u001b[36m1.6611 s\u001b[0m\n",
      " 17\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3533\u001b[0m\t\t\u001b[36m1.7851 s\u001b[0m\n",
      " 18\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3530\u001b[0m\t\t\u001b[36m1.7343 s\u001b[0m\n",
      " 19\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3527\u001b[0m\t\t\u001b[36m1.6848 s\u001b[0m\n",
      " 20\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3524\u001b[0m\t\t\u001b[36m1.5609 s\u001b[0m\n",
      " 21\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3521\u001b[0m\t\t\u001b[36m1.6652 s\u001b[0m\n",
      " 22\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3519\u001b[0m\t\t\u001b[36m1.7894 s\u001b[0m\n",
      " 23\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3517\u001b[0m\t\t\u001b[36m1.6752 s\u001b[0m\n",
      " 24\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3514\u001b[0m\t\t\u001b[36m1.6750 s\u001b[0m\n",
      " 25\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3512\u001b[0m\t\t\u001b[36m1.7604 s\u001b[0m\n",
      " 26\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3511\u001b[0m\t\t\u001b[36m1.7764 s\u001b[0m\n",
      " 27\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3509\u001b[0m\t\t\u001b[36m1.7086 s\u001b[0m\n",
      " 28\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3507\u001b[0m\t\t\u001b[36m1.6843 s\u001b[0m\n",
      " 29\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3505\u001b[0m\t\t\u001b[36m1.7400 s\u001b[0m\n",
      " 30\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3504\u001b[0m\t\t\u001b[36m1.6532 s\u001b[0m\n",
      " 31\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3503\u001b[0m\t\t\u001b[36m1.6676 s\u001b[0m\n",
      " 32\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3501\u001b[0m\t\t\u001b[36m1.7707 s\u001b[0m\n",
      " 33\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3500\u001b[0m\t\t\u001b[36m1.6646 s\u001b[0m\n",
      " 34\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0043\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3499\u001b[0m\t\t\u001b[36m1.6955 s\u001b[0m\n",
      " 35\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3498\u001b[0m\t\t\u001b[36m1.4964 s\u001b[0m\n",
      " 36\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3497\u001b[0m\t\t\u001b[36m1.5130 s\u001b[0m\n",
      " 37\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3496\u001b[0m\t\t\u001b[36m1.5413 s\u001b[0m\n",
      " 38\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3495\u001b[0m\t\t\u001b[36m1.6074 s\u001b[0m\n",
      " 39\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3495\u001b[0m\t\t\u001b[36m1.6166 s\u001b[0m\n",
      " 40\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3494\u001b[0m\t\t\u001b[36m1.7906 s\u001b[0m\n",
      " 41\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3493\u001b[0m\t\t\u001b[36m2.1413 s\u001b[0m\n",
      " 42\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3493\u001b[0m\t\t\u001b[36m1.8495 s\u001b[0m\n",
      " 43\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3492\u001b[0m\t\t\u001b[36m2.6603 s\u001b[0m\n",
      " 44\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3492\u001b[0m\t\t\u001b[36m2.3107 s\u001b[0m\n",
      " 45\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3491\u001b[0m\t\t\u001b[36m1.7054 s\u001b[0m\n",
      " 46\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3491\u001b[0m\t\t\u001b[36m1.6403 s\u001b[0m\n",
      " 47\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3490\u001b[0m\t\t\u001b[36m1.6220 s\u001b[0m\n",
      " 48\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3490\u001b[0m\t\t\u001b[36m1.7123 s\u001b[0m\n",
      " 49\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3490\u001b[0m\t\t\u001b[36m1.6042 s\u001b[0m\n",
      " 50\t  \u001b[32m0.99\u001b[0m/\u001b[35m0.0042\u001b[0m\u001b[32m\t\t0.26\u001b[0m/\u001b[35m0.3489\u001b[0m\t\t\u001b[36m1.5929 s\u001b[0m\n",
      "\u001b[34m\n",
      "--------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m-- Learning finished in 460.7028s. Given number of epochs performed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "net.learning.kw['learning_rate'] = 0.001\n",
    "net.learning.kw['n_epoch'] = 50\n",
    "net.learning.learn_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
